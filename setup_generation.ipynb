{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from xml.etree.ElementTree import XML, fromstring, tostring, ElementTree\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function performs affine transformation. Inputs are: a string variable which is the \n",
    "# name (with path) of the image to transform, three float variables, x and y displacement and \n",
    "# the scale, which will be equal for both dimensions of the picture; the scale only works for\n",
    "# values between 0 and 2, not included.\n",
    "\n",
    "\n",
    "def myaffine(immagine,disp_x,disp_y,scale):\n",
    "    img = cv2.imread(immagine)\n",
    "    M = np.float32([[1,0,disp_x],[0,1,disp_y]]) # traslation matrix\n",
    "    dst = cv2.warpAffine(img,M,(img.shape[1],img.shape[0]))  #dst is the figure displaced\n",
    "    res = cv2.resize(dst,None,fx=scale, fy=scale, interpolation = cv2.INTER_LINEAR) #res is the figure resized\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function variates the gamma of the picture given in input as a string\n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "\n",
    "   invGamma = 1.0 / gamma\n",
    "   table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "   return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function gets a string as input, which is the path and name of the image that will be\n",
    "# transformed as follows: random translation, rescaling, blur, paste of a disturbing image.\n",
    "# It also takes track of the position of the rectangle in which the mode (or the interesting\n",
    "# part of your picture) is inscribed; the output is an open cv2 transformed image and two \n",
    "# arrays with the rectangle coordinates.\n",
    "\n",
    "def myrandtransform(immagine):\n",
    "    disp_x, disp_y=np.random.uniform(-0.45,0.45,2) #chooses a random x and y percentage shift \n",
    "    scala=np.random.uniform(0.33,2) #chooses a random scale\n",
    "    img = cv2.imread(immagine) #read the image\n",
    "    xshape,yshape,colori=img.shape #gets image's shape\n",
    "    shift=(int(xshape*disp_x),int(yshape*disp_y)) #transforms percentage shifts in displacements on the image\n",
    "    \n",
    "    aff=myaffine(immagine,shift[0],shift[1],scala) #operates shifts and rescaling\n",
    "    affx,affy,afcolor=aff.shape\n",
    "    \n",
    "    fiore=myflower(aff) #gets a random flower picture\n",
    "    x_corner_flow=np.random.randint(0,aff.shape[0]-fiore.shape[0]) #chooses a random position toplace the flower on the shifted and rescaled picture, for x...\n",
    "    y_corner_flow=np.random.randint(0,aff.shape[1]-fiore.shape[1]) #...and y dimension\n",
    "    aff[x_corner_flow:x_corner_flow+fiore.shape[0],y_corner_flow:y_corner_flow+fiore.shape[1]]=fiore #pastes the flower on the selected point\n",
    "    \n",
    "    adj = adjust_gamma(aff, gamma=np.random.uniform(1,2)) #changes gamma value\n",
    "    \n",
    "    do_blur=np.random.rand() #we choose wether to blur the image\n",
    "    if do_blur<0.5:\n",
    "        how_blur=np.random.randint(1,5)  #and how to blur it\n",
    "        blur = cv2.blur(adj,(how_blur,how_blur))\n",
    "    else: blur=adj\n",
    "        \n",
    "# Determination of the rectangle; a rectangle is identified by the x and y coordinates on \n",
    "# the picture of two corners: top left and bottom right. Note that coordinates in pictures \n",
    "# are defined as follows: the top left corner has coordinates (0,0), the bottom right has \n",
    "# coordinates (x,y)=(height,width)=(img.shape[0],img.shape[1])=\n",
    "# (number of columns, number of rows)\n",
    "    \n",
    "    \n",
    "    #We start from the identification of the rectangle in the original picture:\n",
    "    A=(int(0.5*(xshape-ex)),int(0.5*(yshape-ey))) #top left (x,y)\n",
    "    B=(A[0]+ex,A[1]+ey)                           #bottom right (x,y)\n",
    "    \n",
    "#calculation of the rectangle after all transformations. Note that it is necessary that\n",
    "#the rectangle is in the picture in a limit of at least 5 pixels, in fact the machine-learning \n",
    "# code will compute the ratio between these rectangle coordinates and the image shape and this \n",
    "# ratio has to be smaller than 1.024127. For this reason we have the max and min evaluations\n",
    "#and...\n",
    "    \n",
    "    x_top_left=max(5,int(scala*(A[0]+shift[0]))+int(0.25*scala*ex))\n",
    "    y_top_left=max(5,int(scala*(A[1]+shift[1]))-int(0.25*scala*ey))\n",
    "    a1=(x_top_left,y_top_left)\n",
    "    x_bottom_right=min(affy-5,int(scala*(B[0]+shift[0]))+int(0.25*scala*ex))\n",
    "    y_bottom_right=min(affx-5,int(scala*(B[1]+shift[1]))-int(0.25*scala*ey))\n",
    "    b1=(x_bottom_right,y_bottom_right)\n",
    "    \n",
    "#... thesw control if\n",
    "    \n",
    "    if(float(a1[0]/affy)>1.024127):\n",
    "        print(immagine+\"\\t a1[0] norm error\")\n",
    "    if(float(a1[1]/affx)>1.024127):\n",
    "        print(immagine+\"\\t a1[1] norm error\")\n",
    "    if(float(b1[0]/affy)>1.024127):\n",
    "        print(immagine+\"\\t b1[0] norm error\")\n",
    "    if(float(b1[1]/affx)>1.024127):\n",
    "        print(immagine+\"\\t b1[1] norm error\")\n",
    "        \n",
    "    #if you want to print the rectangle on your image uncomment the following \n",
    "    #(deprecated in the full generation cycle, suggested in a check of the program)\n",
    "    \n",
    "    #final = cv2.rectangle(blur, a1, b1, (0,255,0), 3)\n",
    "    return (blur,a1,b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function gets an open cv2 image in input, chooses randomly a picture of a flower\n",
    "# which is an object similar to the modes we detect; you can choose different pictures \n",
    "# according to your purposes. These pictures are stored in a folder, whose content is \n",
    "# listed in mylist. The output is an open cv2 image.\n",
    "\n",
    "def myflower(aff):\n",
    "    n=np.random.randint(0,len(mylist)) #random choice\n",
    "    f1 = cv2.imread(flower_path+mylist[n])\n",
    "    fscala=min(1,np.random.uniform(0.05,0.35)*aff.shape[0]/f1.shape[0]) #we want the flower to be sufficiently small not to totally overlap with the mode\n",
    "    fin_flow=myaffine(flower_path+mylist[n],0,0,fscala) #so we properly transform its picture\n",
    "    return fin_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is useful if we want to generate pictures for training in wich there are two\n",
    "# objects to recognize. As this function is used in a cycle, its input is teh integer step of \n",
    "#the cycle. The ouputs are the ones required to write the xml file.\n",
    "\n",
    "def coppie(i): \n",
    "    lx,ly=600,600  #blank image dimensions\n",
    "    blank = np.ones((lx,ly,3),np.uint8)\n",
    "    \n",
    "# We randomly choose two images in our original sampple\n",
    "    \n",
    "    s1=s_modi_studiati[np.random.randint(0,len(s_modi_studiati))]\n",
    "    s2=s_modi_studiati[np.random.randint(0,len(s_modi_studiati))]\n",
    "    im1=cv2.imread(path+'-'+s1+\"_shape.jpg\")\n",
    "    im2=cv2.imread(path+'-'+s2+\"_shape.jpg\")\n",
    "\n",
    "# Calculation of the rectangle in which the mode is inscribed in on of the original pictures\n",
    "    \n",
    "    xshape,yshape,colori=im1.shape\n",
    "    A=(int(0.5*(xshape-ex)),int(0.5*(yshape-ey)))\n",
    "    B=(A[0]+ex,A[1]+ey)\n",
    "\n",
    "# We want to place our pictures on the blank one in such a way that their overlap is \n",
    "# small enough to guarantee a proper learning. Hence we define the variable overlap\n",
    "# and set it to its maximum and a boolean variable flag, we start a cycle in which we \n",
    "# keep placing the images untill the overlap is sufficiently small\n",
    "    \n",
    "    overlap=1.0\n",
    "    flag=1\n",
    "    while(overlap>=0.15 and flag):\n",
    "        rand_top_right_corner_1_x=np.random.randint(0,lx-ex)\n",
    "        rand_top_right_corner_1_y=np.random.randint(0,ly-ey)\n",
    "        rand_top_right_corner_2_x=np.random.randint(0,lx-ex)\n",
    "        rand_top_right_corner_2_y=np.random.randint(0,ly-ey)\n",
    "        A1=(rand_top_right_corner_1_x,rand_top_right_corner_1_y)\n",
    "        A2=(rand_top_right_corner_2_x,rand_top_right_corner_2_y)\n",
    "        B1=(A1[0]+ex,A1[1]+ey)\n",
    "        B2=(A2[0]+ex,A2[1]+ey)\n",
    "        flagx=abs(B2[0]-A1[0])   #x intersection\n",
    "        flagy=abs(B2[1]-A1[1])   #y intersection\n",
    "        if(flagx>2*ex or flagy>2*ey):\n",
    "            flag=0              #it is a case in which the images do not overlap\n",
    "        else: flag=1    #if they overlap, we calculate how big the overlap is\n",
    "        ox=abs(B1[0]-A2[0])   #x side of the rectangle of the intersection\n",
    "        oy=abs(B1[1]-A2[1])   #y side\n",
    "        overlap=float(ox*oy)/(lx*ly)\n",
    "    \n",
    "    #outside the while cycle, the images are correctly placed and we can save the blank one\n",
    "    if float(i/coppie_range) < 0.8:\n",
    "        destin=\"C:/tensorflow1/models/research/object_detection/images/train/\"\n",
    "    else:\n",
    "        destin=\"C:/tensorflow1/models/research/object_detection/images/test/\"\n",
    "    s=\"coppia\"+str(i).zfill(3)+\".jpg\"\n",
    "    blank[A1[0]:B1[0],A1[1]:B1[1]]=im1[A[0]:B[0],A[1]:B[1]]\n",
    "    blank[A2[0]:B2[0],A2[1]:B2[1]]=im2[A[0]:B[0],A[1]:B[1]]\n",
    "    cv2.imwrite(destin+s,blank)\n",
    "    return (s,destin,['modo_meno_'+s1,'modo_meno_'+s2],A1,B1,A2,B2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates an \".xml\" file which will be identical to the one created with a manual\n",
    "# labelling software. Its inputs are:\n",
    "#     flag: str, tells wether the image to be processed has one or two modes to be distiguished\n",
    "#     filename: name of the file without path\n",
    "#     name: name of the class in which the learner must place the image\n",
    "#     path: str\n",
    "#     other: int\n",
    "\n",
    "    \n",
    "\n",
    "def createxml(flag,filename,name,path,width,height,xmin,ymin,xmax,ymax):\n",
    "    s1='<?xml version=\"1.0\" ?>\\n<annotation>\\n\\t\\n\\t\\n\\t<folder>test</folder>\\n\\t\\n\\t\\n\\t<filename>'\n",
    "    s2='</filename>\\n\\t\\n\\t\\n\\t<path>'\n",
    "    #attention, in the following JPG!\n",
    "    s10='.JPG</path>\\n\\t\\n\\t\\n\\t<source>\\n\\t\\t\\n\\t\\t\\n\\t\\t<database>Unknown</database>\\n\\t\\t\\n\\t\\n\\t</source>\\n\\t\\n\\t\\n\\t<size>\\n\\t\\t\\n\\t\\t\\n\\t\\t<width>'\n",
    "    s3='</width>\\n\\t\\t\\n\\t\\t\\n\\t\\t<height>'\n",
    "    s4='</height>\\n\\t\\t\\n\\t\\t\\n\\t\\t<depth>3</depth>\\n\\t\\t\\n\\t\\n\\t</size>\\n\\t\\n\\t\\n\\t<segmented>0</segmented>\\n\\t\\n\\t\\n\\t<object>\\n\\t\\t\\n\\t\\t\\n\\t\\t<name>'\n",
    "    so5='</name>\\n\\t\\t\\n\\t\\t\\n\\t\\t<pose>Unspecified</pose>\\n\\t\\t\\n\\t\\t\\n\\t\\t<truncated>0</truncated>\\n\\t\\t\\n\\t\\t\\n\\t\\t<difficult>0</difficult>\\n\\t\\t\\n\\t\\t\\n\\t\\t<bndbox>\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t<xmin>'\n",
    "    so6='</xmin>\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t<ymin>'\n",
    "    so7='</ymin>\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t<xmax>'\n",
    "    so8='</xmax>\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t<ymax>'\n",
    "    so9='</ymax>\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t</bndbox>\\n\\t\\t\\n\\t\\n\\t</object>'\n",
    "    soo='\\n\\t\\n\\t\\n\\t<object>\\n\\t\\t\\n\\t\\t\\n\\t\\t<name>'\n",
    "    fine='\\n\\t\\n\\n</annotation>\\n'\n",
    "    common_string=s1+filename+s2+path+filename+s10+width+s3+height+s4+name[0]\n",
    "    repeated=so5+xmin[0]+so6+ymin[0]+so7+xmax[0]+so8+ymax[0]+so9\n",
    "    if flag=='simple':\n",
    "        my_xml_string=common_string+repeated+fine\n",
    "    if flag=='coppie':\n",
    "        my_xml_string=common_string+repeated+soo+name[1]+so5+xmin[1]+so6+ymin[1]+so7+xmax[1]+so8+ymax[1]+so9+fine\n",
    "    myxml = fromstring(my_xml_string)\n",
    "    tree = ElementTree(myxml)\n",
    "        \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destin=\"C:/Users/Acanfora/Desktop/motorino_resized/\"\n",
    "\n",
    "path=\"C:/Users/Acanfora/Desktop/motorino_lungo/\"\n",
    "string_name=\"DeviceData_#\"\n",
    "string_number=str(181)\n",
    "estens=\".jpg\"\n",
    "\n",
    "lista=os.listdir(path)[10:260]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following cycle resized a set of images taken in lab\n",
    "\n",
    "for i in range(len(lista)):\n",
    "    final=destin+str(i)+estens\n",
    "    image=cv2.imread(path+string_name+str(i+10).zfill(3)+estens)\n",
    "    height,width,scale=image.shape\n",
    "    ratio=height/width\n",
    "    resized_image = cv2.resize(image, (600, int(600*ratio)))\n",
    "    cv2.imwrite(final,resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/Acanfora/Desktop/motorino_resized/\"\n",
    "flower_path=\"C:/Users/Acanfora/Dropbox/magistrale/II_sem/lab/python/fiori/\"\n",
    "\n",
    "#tx, ty = 600, 451 larghezza, altezza immagini generate da mathematica\n",
    "ex, ey = 290,290 #width, height of modes in my lab pictures\n",
    "fx,fy=244,244 #flowers dimensions\n",
    "\n",
    "mylist = os.listdir(flower_path)  #makes the list of flower images\n",
    "lim=100\n",
    "\n",
    "classi=['uno','due','tre','quattro','cinque']  #learning classes\n",
    "#coppie_range=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#At the end of this cycle we will have 2500 random images placed in the correct folder and\n",
    "#in the correct amount as indicated by the guide you can find in the README file.\n",
    "\n",
    "for i in range(len(lista)):\n",
    "    for k in range(10):\n",
    "        if (i%50) < int(0.8*50):\n",
    "            destin=\"C:/tensorflow1/models/research/object_detection/images/train/\"\n",
    "        else:\n",
    "            destin=\"C:/tensorflow1/models/research/object_detection/images/test/\"\n",
    "        j=(i//50)+1\n",
    "        if ((i+1)%40==0): \n",
    "            print(i,j)\n",
    "        s=str(j)+\"_\"+str(k).zfill(2)+\"_\"+str(i).zfill(3)+\".jpg\"\n",
    "        immagine,a1,b1=myrandtransform(path+str(i)+\".jpg\")\n",
    "        cv2.imwrite(destin+s,immagine)\n",
    "        name=classi[j-1]\n",
    "        tree=createxml('simple',s,[name],destin,str(immagine.shape[1]),str(immagine.shape[0]),[str(a1[0])],[str(a1[1])],[str(b1[0])],[str(b1[1])])\n",
    "        tree.write(destin+s[:-3]+\"xml\")\n",
    "winsound.Beep(500,1000)  #makes a beep when the cycle is done to wake you up after \n",
    "#those 2 or 3 minutes it takes\n",
    "\n",
    "                                                                 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
